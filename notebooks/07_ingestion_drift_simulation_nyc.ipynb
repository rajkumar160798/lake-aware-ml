{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb767573",
   "metadata": {},
   "source": [
    "# 07_ingestion_drift_simulation_nyc\n",
    "\n",
    "Simulate ingestion drift (missing partition, partial ingestion, delayed ingestion) on NYC Taxi monthly partitions and analyze partition-level metrics and downstream regression impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_2samp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43464d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Collect monthly files (partitions)\n",
    "files = sorted(glob.glob(os.path.join('..','data','nyc_taxi','*.csv')) )\n",
    "print('Found partitions:', files)\n",
    "# deterministic sampling fraction\n",
    "SAMPLE_FRAC = 0.01\n",
    "RANDOM_STATE = 42\n",
    "def load_partition(path, sample_frac=SAMPLE_FRAC):\n",
    "    # memory-efficient deterministic sample\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    if sample_frac < 1.0:\n",
    "        df = df.sample(frac=sample_frac, random_state=RANDOM_STATE)\n",
    "    # attach partition id from filename\n",
    "    pid = os.path.basename(path).replace('.csv','')\n",
    "    df['partition'] = pid\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eba8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all partitions with deterministic sampling\n",
    "parts = []\n",
    "for p in files:\n",
    "    try:\n",
    "        parts.append(load_partition(p))\n",
    "    except Exception as e:\n",
    "        print('Error loading', p, e)\n",
    "df_all = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "print('Concatenated shape:', df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21120eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic ingestion metrics per partition before simulation\n",
    "metric_cols = []\n",
    "for c in ['trip_distance','fare_amount']:\n",
    "    if c in df_all.columns:\n",
    "        metric_cols.append(c)\n",
    "grouped = df_all.groupby('partition').agg(row_count=('partition','size'))\n",
    "for c in metric_cols:\n",
    "    grouped[c + '_mean'] = df_all.groupby('partition')[c].mean()\n",
    "grouped = grouped.reset_index()\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f28214",
   "metadata": {},
   "source": [
    "## Ingestion Drift Scenarios\n",
    "We will simulate Missing Partition, Partial Ingestion and Delayed Ingestion and compare partition-level metrics before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72888930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario A: Missing Partition — remove a specific month if available (e.g., contains '2016-02')\n",
    "target_month = None\n",
    "for f in files:\n",
    "    if '2016-02' in f:\n",
    "        target_month = f; break\n",
    "if target_month is None and files:\n",
    "    # fallback: choose middle partition\n",
    "    target_month = files[len(files)//2]\n",
    "print('Simulating missing partition:', os.path.basename(target_month))\n",
    "parts_missing = [load_partition(p) for p in files if p != target_month]\n",
    "df_missing = pd.concat(parts_missing, ignore_index=True)\n",
    "group_missing = df_missing.groupby('partition').agg(row_count=('partition','size'))\n",
    "for c in metric_cols:\n",
    "    group_missing[c + '_mean'] = df_missing.groupby('partition')[c].mean()\n",
    "group_missing = group_missing.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a064e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario B: Partial ingestion — retain only 50% rows for the last partition\n",
    "if files:\n",
    "    last = files[-1]\n",
    "    parts_partial = [load_partition(p) for p in files[:-1]]\n",
    "    parts_partial.append(load_partition(last, sample_frac=0.5))\n",
    "    df_partial = pd.concat(parts_partial, ignore_index=True)\n",
    "    group_partial = df_partial.groupby('partition').agg(row_count=('partition','size'))\n",
    "    for c in metric_cols:\n",
    "        group_partial[c + '_mean'] = df_partial.groupby('partition')[c].mean()\n",
    "    group_partial = group_partial.reset_index()\n",
    "else:\n",
    "    group_partial = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario C: Delayed ingestion — shuffle partition ordering to simulate late arrival of one partition\n",
    "if len(files) > 1:\n",
    "    delayed_idx = 0\n",
    "    shuffled = files.copy()\n",
    "    # move the chosen partition to the end to simulate delay\n",
    "    p = shuffled.pop(delayed_idx)\n",
    "    shuffled.append(p)\n",
    "    parts_delayed = [load_partition(pp) for pp in shuffled]\n",
    "    df_delayed = pd.concat(parts_delayed, ignore_index=True)\n",
    "    group_delayed = df_delayed.groupby('partition').agg(row_count=('partition','size'))\n",
    "    for c in metric_cols:\n",
    "        group_delayed[c + '_mean'] = df_delayed.groupby('partition')[c].mean()\n",
    "    group_delayed = group_delayed.reset_index()\n",
    "else:\n",
    "    group_delayed = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c537a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics before and after and save tables/plots\n",
    "os.makedirs(os.path.join('..','results','figures'), exist_ok=True)\n",
    "os.makedirs(os.path.join('..','results','tables'), exist_ok=True)\n",
    "grouped.to_csv(os.path.join('..','results','tables','07_baseline_partition_metrics.csv'), index=False)\n",
    "group_missing.to_csv(os.path.join('..','results','tables','07_missing_partition_metrics.csv'), index=False)\n",
    "group_partial.to_csv(os.path.join('..','results','tables','07_partial_partition_metrics.csv'), index=False)\n",
    "group_delayed.to_csv(os.path.join('..','results','tables','07_delayed_partition_metrics.csv'), index=False)\n",
    "# Plot record volume over time for baseline and scenarios\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.lineplot(data=grouped, x='partition', y='row_count', marker='o', label='baseline')\n",
    "sns.lineplot(data=group_missing, x='partition', y='row_count', marker='o', label='missing_partition')\n",
    "sns.lineplot(data=group_partial, x='partition', y='row_count', marker='o', label='partial_ingestion')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Row count (sampled)')\n",
    "plt.title('Partition record volume (sampled)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('..','results','figures','07_partition_volume.png'), dpi=300)\n",
    "plt.show()\n",
    "# Plot mean trip distance over time and annotate missing partition event\n",
    "if 'trip_distance_mean' in grouped.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.lineplot(data=grouped, x='partition', y='trip_distance_mean', marker='o', label='baseline')\n",
    "    sns.lineplot(data=group_missing, x='partition', y='trip_distance_mean', marker='o', label='missing')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Mean trip distance')\n",
    "    plt.title('Mean trip distance over partitions')\n",
    "    # annotate the removed partition if known\n",
    "    removed = os.path.basename(target_month).replace('.csv','')\n",
    "    plt.annotate('missing', xy=(removed, 0), xytext=(removed, grouped['trip_distance_mean'].max()), arrowprops=dict(arrowstyle='->')) if removed in grouped['partition'].values else None\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('..','results','figures','07_trip_distance_over_time.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82d2db",
   "metadata": {},
   "source": [
    "## Research notes\n",
    "- Ingestion drift changes the data available at the lake layer — missing partitions or partial ingestions cause downstream statistics and models to shift before any ML training occurs.\n",
    "- Deterministic sampling preserves reproducibility for experiments while keeping memory use low."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
