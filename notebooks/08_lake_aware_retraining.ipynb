{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess AI4I like notebook 05\n",
    "path = os.path.join('..','data','ai4i','ai4i2020.csv')\n",
    "df = pd.read_csv(path)\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(r'[^0-9a-z]+','_', regex=True).str.strip('_')\n",
    "if 'machine_failure' not in df.columns:\n",
    "    raise RuntimeError('machine_failure not found')\n",
    "df['machine_failure'] = df['machine_failure'].astype(int)\n",
    "order_col = 'udi' if 'udi' in df.columns else df.columns[0]\n",
    "data = df.select_dtypes(include=[np.number]).dropna(subset=['machine_failure']).reset_index(drop=True)\n",
    "data = data.sort_values(order_col).reset_index(drop=True)\n",
    "n = len(data); train_end = int(0.6 * n)\n",
    "train = data.iloc[:train_end].copy(); stream = data.iloc[train_end:].copy()\n",
    "X_train = train.drop(columns=['machine_failure', order_col]); y_train = train['machine_failure']\n",
    "X_stream = stream.drop(columns=['machine_failure', order_col]); y_stream = stream['machine_failure']\n",
    "# baseline model\n",
    "RANDOM_STATE = 42\n",
    "base_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "base_model.fit(X_train, y_train)\n",
    "print('Baseline trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266cc487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for simulated drift and KS-based detector\n",
    "drift_feats = [f for f in ['air_temperature_k','process_temperature_k'] if f in X_train.columns]\n",
    "def ks_score(batch):\n",
    "    vals = []\n",
    "    for f in drift_feats:\n",
    "        vals.append(ks_2samp(X_train[f].values, batch[f].values).statistic)\n",
    "    return np.mean(vals) if vals else 0.0\n",
    "\n",
    "def apply_gauss(X, feats, sigma_factor, rs=RANDOM_STATE):\n",
    "    Xp = X.copy(); rng = np.random.RandomState(rs)\n",
    "    for f in feats:\n",
    "        sigma = Xp[f].std() * sigma_factor\n",
    "        Xp[f] = Xp[f] + rng.normal(0, sigma, size=len(Xp))\n",
    "    return Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7017c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "window_size = max(50, int(0.05 * len(X_stream)))\n",
    "threshold = 0.1\n",
    "n_windows = int(np.ceil(len(X_stream)/window_size))\n",
    "# strategies state holders\n",
    "results = {'static':[], 'periodic':[], 'lake_aware':[]}\n",
    "# prepare models for each strategy\n",
    "model_static = base_model\n",
    "model_periodic = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "model_periodic.fit(X_train, y_train)\n",
    "model_lake = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "model_lake.fit(X_train, y_train)\n",
    "# periodic retrain interval (windows)\n",
    "period = 3\n",
    "retrain_counts = {'static':0, 'periodic':0, 'lake_aware':0}\n",
    "# iterate windows and optionally inject simulated drift into certain windows\n",
    "for w in range(n_windows):\n",
    "    start = w * window_size; end = min(len(X_stream), (w+1)*window_size)\n",
    "    Xw = X_stream.iloc[start:end].copy(); yw = y_stream.iloc[start:end]\n",
    "    # for this experiment inject moderate gaussian drift on window indices divisible by 4\n",
    "    if w % 4 == 0:\n",
    "        Xw_d = apply_gauss(Xw, drift_feats, sigma_factor=1.0, rs=RANDOM_STATE + w)\n",
    "    else:\n",
    "        Xw_d = Xw.copy()\n",
    "    # static: evaluate without retraining\n",
    "    ypred_s = model_static.predict(Xw_d)\n",
    "    results['static'].append(accuracy_score(yw, ypred_s))\n",
    "    # periodic: retrain every `period` windows using accumulated data\n",
    "    if w % period == 0 and w>0:\n",
    "        # retrain on all seen stream data (simple simulation)\n",
    "        seen = X_stream.iloc[:end]; seen_y = y_stream.iloc[:end]\n",
    "        model_periodic = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        model_periodic.fit(pd.concat([X_train, seen]), pd.concat([y_train, seen_y]))\n",
    "        retrain_counts['periodic'] += 1\n",
    "    ypred_p = model_periodic.predict(Xw_d)\n",
    "    results['periodic'].append(accuracy_score(yw, ypred_p))\n",
    "    # lake-aware: compute KS and retrain only when above threshold\n",
    "    score = ks_score(Xw_d)\n",
    "    if score > threshold:\n",
    "        seen = X_stream.iloc[:end]; seen_y = y_stream.iloc[:end]\n",
    "        model_lake = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        model_lake.fit(pd.concat([X_train, seen]), pd.concat([y_train, seen_y]))\n",
    "        retrain_counts['lake_aware'] += 1\n",
    "    ypred_l = model_lake.predict(Xw_d)\n",
    "    results['lake_aware'].append(accuracy_score(yw, ypred_l))\n",
    "\n",
    "# collect results into dataframe\n",
    "time_idx = list(range(n_windows))\n",
    "res_df = pd.DataFrame({'window':time_idx, 'static_acc':results['static'], 'periodic_acc':results['periodic'], 'lake_acc':results['lake_aware']})\n",
    "print('Retrain counts:', retrain_counts)\n",
    "os.makedirs(os.path.join('..','results','figures'), exist_ok=True)\n",
    "res_df.to_csv(os.path.join('..','results','tables','08_retraining_accuracy_over_time.csv'), index=False)\n",
    "# Plot accuracy over time for the three strategies\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(res_df['window'], res_df['static_acc'], marker='o', label='static')\n",
    "plt.plot(res_df['window'], res_df['periodic_acc'], marker='o', label='periodic')\n",
    "plt.plot(res_df['window'], res_df['lake_acc'], marker='o', label='lake_aware')\n",
    "plt.xlabel('Window index')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over time by retraining strategy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('..','results','figures','08_accuracy_over_time.png'), dpi=300)\n",
    "plt.show()\n",
    "# Cost vs accuracy trade-off: cost = number of retrains (proxy)\n",
    "costs = {'static':0, 'periodic':retrain_counts['periodic'], 'lake_aware':retrain_counts['lake_aware']}\n",
    "final_acc = {'static':res_df['static_acc'].mean(), 'periodic':res_df['periodic_acc'].mean(), 'lake_aware':res_df['lake_acc'].mean()}\n",
    "cost_df = pd.DataFrame([{'strategy':k, 'retrain_count':v, 'mean_accuracy':final_acc[k]} for k,v in costs.items()])\n",
    "cost_df.to_csv(os.path.join('..','results','tables','08_retrain_costs.csv'), index=False)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(data=cost_df, x='retrain_count', y='mean_accuracy', hue='strategy', s=150)\n",
    "plt.xlabel('Retrain count (proxy cost)')\n",
    "plt.ylabel('Mean accuracy over stream')\n",
    "plt.title('Cost vs Accuracy trade-off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('..','results','figures','08_cost_vs_accuracy.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c3ebe",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Lake-aware retraining triggers retraining only when distributional shift (KS) exceeds a threshold, reducing unnecessary retrains.\n",
    "- Design choices (window size, threshold) are configurable and should be tuned for production."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
