{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ef8ec7",
   "metadata": {},
   "source": [
    "# 06_schema_drift_ai4i\n",
    "\n",
    "Objective: simulate schema drift for the AI4I dataset by dropping a feature, renaming a column, and introducing a missing feature. Evaluate whether the pipeline breaks, performance degrades, and whether metadata-aware checks detect the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "markdown\n",
    "markdown\n",
    "md-01\n",
    "# 06_schema_drift_ai4i\n",
    "\n",
    "This notebook simulates schema evolution (removal, renaming, missing values) and evaluates impact on an ML pipeline. It follows preprocessing used in the feature-drift notebook to ensure comparability.\n",
    "code\n",
    "python\n",
    "code-01\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')\n",
    "code\n",
    "python\n",
    "code-02\n",
    "# Load and preprocess using same steps as notebook 05\n",
    "path = os.path.join('..','data','ai4i','ai4i2020.csv')\n",
    "raw = pd.read_csv(path)\n",
    "raw.columns = raw.columns.str.strip().str.lower().str.replace(r'[^0-9a-z]+','_', regex=True).str.strip('_')\n",
    "# check target\n",
    "if 'machine_failure' not in raw.columns:\n",
    "    raise RuntimeError('machine_failure not found')\n",
    "raw['machine_failure'] = raw['machine_failure'].astype(int)\n",
    "# keep numeric features and udi for ordering\n",
    "order_col = 'udi' if 'udi' in raw.columns else raw.columns[0]\n",
    "data = raw.select_dtypes(include=[np.number]).copy()\n",
    "data = data.dropna(subset=['machine_failure']).reset_index(drop=True)\n",
    "# time-based split consistent with notebook 05\n",
    "data = data.sort_values(order_col).reset_index(drop=True)\n",
    "n = len(data); train_end = int(0.6 * n)\n",
    "train = data.iloc[:train_end].copy(); test = data.iloc[train_end:].copy()\n",
    "X_train = train.drop(columns=['machine_failure', order_col]); y_train = train['machine_failure']\n",
    "X_test = test.drop(columns=['machine_failure', order_col]); y_test = test['machine_failure']\n",
    "print('Prepared shapes:', X_train.shape, X_test.shape)\n",
    "code\n",
    "python\n",
    "code-03\n",
    "# Train baseline model on original schema\n",
    "RANDOM_STATE = 42\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "baseline_acc = accuracy_score(y_test, y_pred)\n",
    "baseline_f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "print('Baseline — Acc:{:.4f} F1:{:.4f}'.format(baseline_acc, baseline_f1))\n",
    "markdown\n",
    "markdown\n",
    "md-02\n",
    "## Schema Drift Scenarios\n",
    "We simulate three realistic schema evolutions and capture whether the pipeline crashes or degrades gracefully.\n",
    "code\n",
    "python\n",
    "code-04\n",
    "results = []\n",
    "# Scenario A: Feature Removal (torque_nm)\n",
    "feat_remove = 'torque_nm'\n",
    "X_test_rm = X_test.copy()\n",
    "if feat_remove in X_test_rm.columns:\n",
    "    X_test_rm = X_test_rm.drop(columns=[feat_remove])\n",
    "# metadata-aware check\n",
    "expected = set(X_train.columns)\n",
    "current = set(X_test_rm.columns)\n",
    "missing = list(expected - current)\n",
    "scenario = 'feature_removal'\n",
    "info = {'scenario':scenario, 'missing_cols': missing}\n",
    "# Try inference and capture outcome\n",
    "try:\n",
    "    y_pred_rm = clf.predict(X_test_rm)\n",
    "    acc_rm = accuracy_score(y_test, y_pred_rm)\n",
    "    info.update({'crashed':False, 'accuracy':acc_rm})\n",
    "except Exception as e:\n",
    "    # pipeline crashed due to schema mismatch; try a fallback by adding missing cols as zeros\n",
    "    X_test_fix = X_test_rm.copy()\n",
    "    for c in missing:\n",
    "        X_test_fix[c] = 0\n",
    "    # ensure column order\n",
    "    X_test_fix = X_test_fix[X_train.columns]\n",
    "    y_pred_fix = clf.predict(X_test_fix)\n",
    "    acc_fix = accuracy_score(y_test, y_pred_fix)\n",
    "    info.update({'crashed':True, 'error':str(e), 'accuracy_fallback':acc_fix})\n",
    "results.append(info)\n",
    "code\n",
    "python\n",
    "code-05\n",
    "# Scenario B: Feature Renaming (process_temperature_k -> proc_temp_k)\n",
    "old = 'process_temperature_k'\n",
    "new = 'proc_temp_k'\n",
    "X_test_ren = X_test.copy()\n",
    "if old in X_test_ren.columns:\n",
    "    X_test_ren = X_test_ren.rename(columns={old:new})\n",
    "scenario = 'feature_rename'\n",
    "info = {'scenario':scenario}\n",
    "try:\n",
    "    y_pred_ren = clf.predict(X_test_ren)\n",
    "    acc_ren = accuracy_score(y_test, y_pred_ren)\n",
    "    info.update({'crashed':False, 'accuracy':acc_ren})\n",
    "except Exception as e:\n",
    "    # attempt naive fix: map new name back to expected by copying column if possible\n",
    "    X_test_fix = X_test_ren.copy()\n",
    "    if new in X_test_fix.columns:\n",
    "        X_test_fix[old] = X_test_fix[new]\n",
    "    # add any missing columns as zeros\n",
    "    for c in set(X_train.columns) - set(X_test_fix.columns):\n",
    "        X_test_fix[c] = 0\n",
    "    X_test_fix = X_test_fix[X_train.columns]\n",
    "    y_pred_fix = clf.predict(X_test_fix)\n",
    "    acc_fix = accuracy_score(y_test, y_pred_fix)\n",
    "    info.update({'crashed':True, 'error':str(e), 'accuracy_fallback':acc_fix})\n",
    "results.append(info)\n",
    "code\n",
    "python\n",
    "code-06\n",
    "# Scenario C: Missing Feature Injection (30% NaNs in a key feature)\n",
    "key = 'process_temperature_k' if 'process_temperature_k' in X_test.columns else X_test.columns[0]\n",
    "X_test_nan = X_test.copy()\n",
    "rng = np.random.RandomState(42)\n",
    "idx = rng.choice(X_test_nan.index, size=int(0.3 * len(X_test_nan)), replace=False)\n",
    "X_test_nan.loc[idx, key] = np.nan\n",
    "scenario = 'missing_injection'\n",
    "info = {'scenario':scenario, 'nan_fraction':0.3, 'key':key}\n",
    "# RandomForest cannot handle NaN; attempt imputation then predict\n",
    "try:\n",
    "    # simple impute with column mean from train\n",
    "    col_mean = X_train[key].mean()\n",
    "    X_test_imp = X_test_nan.copy()\n",
    "    X_test_imp[key] = X_test_imp[key].fillna(col_mean)\n",
    "    y_pred_imp = clf.predict(X_test_imp)\n",
    "    acc_imp = accuracy_score(y_test, y_pred_imp)\n",
    "    info.update({'crashed':False, 'accuracy':acc_imp})\n",
    "except Exception as e:\n",
    "    info.update({'crashed':True, 'error':str(e)})\n",
    "results.append(info)\n",
    "code\n",
    "python\n",
    "code-07\n",
    "# Summarize results into a comparison table and plot performance degradation\n",
    "res_df = pd.DataFrame(results)\n",
    "print(res_df)\n",
    "os.makedirs(os.path.join('..','results','figures'), exist_ok=True)\n",
    "os.makedirs(os.path.join('..','results','tables'), exist_ok=True)\n",
    "# Prepare a simple accuracy column (use fallback if provided)\n",
    "def pick_acc(row):\n",
    "    if 'accuracy' in row and not pd.isna(row['accuracy']):\n",
    "        return row['accuracy']\n",
    "    if 'accuracy_fallback' in row and not pd.isna(row['accuracy_fallback']):\n",
    "        return row['accuracy_fallback']\n",
    "    return np.nan\n",
    "res_df['accuracy_effective'] = res_df.apply(pick_acc, axis=1)\n",
    "res_df.to_csv(os.path.join('..','results','tables','06_schema_drift_summary.csv'), index=False)\n",
    "# Plot performance degradation\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(data=res_df, x='scenario', y='accuracy_effective')\n",
    "plt.ylabel('Accuracy (after schema change)')\n",
    "plt.title('Model performance under schema drift scenarios')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('..','results','figures','06_schema_drift_performance.png'), dpi=300)\n",
    "plt.show()\n",
    "markdown\n",
    "markdown\n",
    "md-03\n",
    "## Research notes\n",
    "- In data lakes, schema evolution (columns renamed/removed) is common; pipelines should verify expected schema via metadata before inference.\n",
    "- Our simple fallback (adding missing columns with zeros or mapping renamed columns) shows graceful degradation but may hide silent performance loss — metadata tracking avoids surprises."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
